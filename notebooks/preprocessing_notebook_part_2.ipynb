{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f8a4799-8ec8-4ee4-8f74-88b144c58433",
   "metadata": {},
   "source": [
    " This notebook is responsible for aggregating the data set into one large dataframe/parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4e32723-35b5-403f-8fd8-3c08dc751cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e810aaa2-30e6-45a4-b548-faa61f3a779f",
   "metadata": {},
   "source": [
    "Read in all the data and group it accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee77b7f7-2a50-4dbb-906f-818dfd87f30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/02 12:14:04 WARN Utils: Your hostname, Sens-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 10.12.253.187 instead (on interface en0)\n",
      "22/08/02 12:14:04 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/02 12:14:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Tutorial 1\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.driver.memory\", \"8g\")\n",
    "    .config(\"spark.sql.parquet.enableVectorizedReader\", False)\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e3cec8f-89e5-4234-bb61-ec6c60475444",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_taxi = spark.read.parquet('../data/raw/taxi_data/*.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "683f4000-9d5d-4fb8-a8ad-d11543b521cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_weather = spark.read.option(\"header\", True).csv('../data/raw/weather_data.csv')\n",
    "sdf_weather = sdf_weather.withColumn(\n",
    "        'DATE',\n",
    "        F.col('DATE').cast('date'))\n",
    "sdf_weather = sdf_weather.filter((F.year(sdf_weather.DATE) == 2017) | (F.year(sdf_weather.DATE) == 2018))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da379e52-6150-47f2-9d9b-9b4a2538bba7",
   "metadata": {},
   "source": [
    "Reduce dataframes to only the desired attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6cc47af6-c6ab-4991-b7dd-0eca6d03ae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_weather = sdf_weather.select(\"DATE\", \"PRCP\", \"SNOW\", \"TMAX\", \"TMIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3d96ab1-94e5-493e-8f1d-f8c7ad63502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_taxi = sdf_taxi.select(\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\", \"payment_type\", \"trip_distance\", \"PULocationID\", \"DOLocationID\", \"fare_amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a206b5e0-31ea-47bf-b0d3-2f37ce42aaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------\n",
      " DATE | 2017-01-01 \n",
      " PRCP |     0      \n",
      " SNOW |     0      \n",
      " TMAX |    89      \n",
      " TMIN |    44      \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_weather.show(1, vertical = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eb3bd67-b9e2-4bed-b77c-b51aa20b4a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------\n",
      " tpep_pickup_datetime  | 2017-01-01 11:32:05 \n",
      " tpep_dropoff_datetime | 2017-01-01 11:37:48 \n",
      " passenger_count       | 1                   \n",
      " payment_type          | 2                   \n",
      " trip_distance         | 1.2                 \n",
      " PULocationID          | 140                 \n",
      " DOLocationID          | 236                 \n",
      " fare_amount           | 6.5                 \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_taxi.show(1, vertical = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "734dfc27-2199-4d75-b455-f7471302952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = sdf_taxi.join(sdf_weather, F.to_date(\"tpep_pickup_datetime\") == F.col(\"DATE\"), \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a350c9b-10d5-4295-845d-2324e31b8492",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------\n",
      " tpep_pickup_datetime  | 2017-01-01 11:32:05 \n",
      " tpep_dropoff_datetime | 2017-01-01 11:37:48 \n",
      " passenger_count       | 1                   \n",
      " payment_type          | 2                   \n",
      " trip_distance         | 1.2                 \n",
      " PULocationID          | 140                 \n",
      " DOLocationID          | 236                 \n",
      " fare_amount           | 6.5                 \n",
      " DATE                  | 2017-01-01          \n",
      " PRCP                  |     0               \n",
      " SNOW                  |     0               \n",
      " TMAX                  |    89               \n",
      " TMIN                  |    44               \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.show(1, vertical = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
